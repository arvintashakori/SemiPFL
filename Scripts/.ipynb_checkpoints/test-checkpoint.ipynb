{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import HN, Autoencoder, BASEModel, MODEL\n",
    "from collections import OrderedDict, defaultdict\n",
    "from utils import get_default_device, set_seed, f1_loss\n",
    "from node import Clients\n",
    "\n",
    "import os\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class parameters:\n",
    "    def __init__(self):\n",
    "        self.seed = 0\n",
    "        self.labels_list = ['JOG', 'JUM', 'STD', 'WAL']  # list of activities\n",
    "        self.outputdim = len(self.labels_list)\n",
    "        # self.data_address = r\"C:\\Users\\walke\\Documents\\GitHub\\SemiPFL_Wenwen\\MobiNpy_4_Act\"  # data adress\n",
    "        self.data_address = os.path.abspath(os.path.join(\n",
    "            os.getcwd(), os.pardir)) + \"/Datasets/MobiNpy_4_Act/\"  # data adress\n",
    "        self.trial_number = 1  # which trial we use for this test\n",
    "        self.label_ratio = 0.10  # ratio of labeled data\n",
    "        self.eval_ratio = 0.30  # ratio of eval data\n",
    "        self.number_of_client = 1  # total number of clients\n",
    "        self.server_ID = [0]  # server ID\n",
    "        self.batch_size = 128  # training batch size\n",
    "        self.window_size = 30  # window size (for our case 30)\n",
    "        self.width = 9  # data dimension (AX, AY, AZ) (GX, GY, GZ) (MX, MY, MZ)\n",
    "        self.n_kernels = 16  # number of kernels for hypernetwork\n",
    "        self.total_number_of_clients = 59  # total number of subjects (client + server)\n",
    "        self.learning_rate = 1e-4  # learning rate for optimizer\n",
    "        self.steps = 10  # total number of epochs\n",
    "        self.inner_step_for_AE = 5  # number of epochs to fine tunne the Autoencoder\n",
    "        self.inner_step_server_finetune = 5  # number of steps in the server side to finetune\n",
    "        self.inner_step_for_model = 5  # number of steps that server fine tune its hn and user embedding parameters\n",
    "        self.model_loop = False  # feedback loop for user model\n",
    "        self.inner_step_for_client = 5  # number of steps that user fine tune its model\n",
    "        self.inner_lr = 1e-4  # user learning rate\n",
    "        self.inner_wd = 5e-5  # weight decay\n",
    "        self.inout_channels = 1  # number of channels\n",
    "        self.hidden = 16  # Autoencoder layer 2 parameters\n",
    "        self.n_kernels_enc = 3  # autoencoder encoder kernel size\n",
    "        self.hidden_dim_for_HN = 100  # hidden dimension for hypernetwork\n",
    "        self.n_kernels_dec = 3  # autoencoder decoder kernel size\n",
    "        self.latent_rep = 4  # latent reperesentation size\n",
    "        self.n_hidden_HN = 100  # number of hidden layers in hypernetworks\n",
    "        self.stride_value = 1  # stride value for autoencoder\n",
    "        self.padding_value = 1  # padding value for autoencoder\n",
    "        self.model_hidden_layer =128  # final model hidden layer size\n",
    "        self.spec_norm = False  # True if you want to use spectral norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = parameters()\n",
    "set_seed(params.seed)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "device = get_default_device()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL(inout_channels=params.inout_channels, hidden=params.hidden, n_kernels_enc=params.n_kernels_enc,\n",
    "                     n_kernels_dec=params.n_kernels_dec, latent_rep=params.latent_rep, stride_value=params.stride_value,\n",
    "                     padding_value=params.padding_value, latent_rep_fc= 4 * 3 * 6, out_dim=params.outputdim, hidden_layer=params.model_hidden_layer)  # initializing the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODEL(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(3, 5), stride=(3, 5), padding=0, dilation=1, ceil_mode=False)\n",
       "  (batch1): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=72, out_features=128, bias=True)\n",
       "  (batch2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " criteria_model = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1f30bd1b324a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hnet' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=hnet.parameters(), lr=params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
