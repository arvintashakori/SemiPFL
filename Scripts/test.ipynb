{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import HN, Autoencoder, BASEModel\n",
    "from collections import OrderedDict, defaultdict\n",
    "from utils import get_default_device, set_seed, f1_loss\n",
    "from node import Clients\n",
    "\n",
    "import os\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class parameters:\n",
    "    def __init__(self):\n",
    "        self.seed = 0\n",
    "        self.labels_list = ['JOG', 'JUM', 'STD', 'WAL']  # list of activities\n",
    "        self.outputdim = len(self.labels_list)\n",
    "        self.data_address = os.path.abspath(os.path.join(\n",
    "            os.getcwd(), os.pardir)) + \"/Datasets/MobiNpy_4_Act/\"  # data adress\n",
    "        self.trial_number = 0  # which trial we use for this test\n",
    "        self.label_ratio = 0.10  # ratio of labeled data\n",
    "        self.eval_ratio = 0.30  # ratio of eval data\n",
    "        self.number_of_client = 1  # total number of clients\n",
    "        self.server_ID = [0]  # server ID\n",
    "        self.batch_size = 128  # training batch size\n",
    "        self.window_size = 30  # window size (for our case 30)\n",
    "        self.width = 9  # data dimension (AX, AY, AZ) (GX, GY, GZ) (MX, MY, MZ)\n",
    "        self.n_kernels = 16  # number of kernels for hypernetwork\n",
    "        self.total_number_of_clients = 59  # total number of subjects (client + server)\n",
    "        self.learning_rate = 1e-3  # learning rate for optimizer\n",
    "        self.steps = 10  # total number of epochs\n",
    "        self.inner_step_for_AE = 20  # number of epochs to fine tunne the Autoencoder\n",
    "        self.inner_step_server_finetune = 20  # number of steps in the server side to finetune\n",
    "        self.inner_step_for_model = 20  # number of steps that server fine tune its hn and user embedding parameters\n",
    "        self.model_loop = False  # feedback loop for user model\n",
    "        self.inner_step_for_client = 20  # number of steps that user fine tune its model\n",
    "        self.inner_lr = 1e-3  # user learning rate\n",
    "        self.inner_wd = 5e-5  # weight decay\n",
    "        self.inout_channels = 1  # number of channels\n",
    "        self.hidden = 16  # Autoencoder layer 2 parameters\n",
    "        self.n_kernels_enc = 3  # autoencoder encoder kernel size\n",
    "        self.hidden_dim_for_HN = 100  # hidden dimension for hypernetwork\n",
    "        self.n_kernels_dec = 3  # autoencoder decoder kernel size\n",
    "        self.latent_rep = 1  # latent reperesentation size\n",
    "        self.n_hidden_HN = 1  # number of hidden layers in hypernetworks\n",
    "        self.stride_value = 1  # stride value for autoencoder\n",
    "        self.padding_value = 1  # padding value for autoencoder\n",
    "        self.model_hidden_layer = 128  # final model hidden layer size\n",
    "        self.spec_norm = False  # True if you want to use spectral norm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "params = parameters()\n",
    "set_seed(params.seed)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "device = get_default_device()\n",
    "\n",
    "# laoding data\n",
    "nodes = Clients(address=params.data_address,\n",
    "                    trial_number=params.trial_number,\n",
    "                    label_ratio=params.label_ratio,\n",
    "                    server_ID=params.server_ID,\n",
    "                    eval_ratio=params.eval_ratio,\n",
    "                    window_size=params.window_size,\n",
    "                    width=params.width,\n",
    "                    transform=transform,\n",
    "                    num_user=params.total_number_of_clients)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "client_loader = []\n",
    "client_labeled_loaders = []\n",
    "eval_loader = []\n",
    "server_loaders = torch.utils.data.DataLoader(nodes.server_loaders, batch_size=params.batch_size, shuffle=True)\n",
    "\n",
    "for i in range(params.number_of_client):\n",
    "    client_loader.append(torch.utils.data.DataLoader(nodes.client_loaders[i], batch_size=params.batch_size, shuffle=True))\n",
    "    client_labeled_loaders.append(torch.utils.data.DataLoader(nodes.client_labeled_loaders[i], batch_size=params.batch_size, shuffle=True))\n",
    "    eval_loader.append(torch.utils.data.DataLoader(nodes.eval_data[i], batch_size=params.batch_size, shuffle=True))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "BASEModel(\n  (fc1): Linear(in_features=270, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=4, bias=True)\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE = Autoencoder(inout_channels=params.inout_channels, hidden=params.hidden, n_kernels_enc=params.n_kernels_enc,\n",
    "                     n_kernels_dec=params.n_kernels_dec, latent_rep=params.latent_rep, stride_value=params.stride_value,\n",
    "                     padding_value=params.padding_value)  # initializing the autoencoder\n",
    "model = BASEModel(latent_rep=params.width * params.window_size * params.latent_rep,\n",
    "                      out_dim=params.outputdim, hidden_layer=params.model_hidden_layer)  # initilizing the base model\n",
    "\n",
    "# send models to device\n",
    "\n",
    "AE.to(device)\n",
    "model.to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# init inner optimizer\n",
    "inner_optim = torch.optim.Adam(AE.parameters(), lr=params.inner_lr, weight_decay=params.inner_wd)\n",
    "criteria_AE = torch.nn.BCEWithLogitsLoss()\n",
    "criteria_model = torch.nn.NLLLoss()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "AE.train()\n",
    "for i in range(params.inner_step_server_finetune):\n",
    "    inner_optim.zero_grad()\n",
    "    for sensor_values, _ in client_loader[0]:\n",
    "        predicted_sensor_values = AE(sensor_values.to(device).float())\n",
    "        loss = criteria_AE(sensor_values.to(device).float(), predicted_sensor_values.to(device))\n",
    "        loss.backward()\n",
    "        inner_optim.step()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.905244053765567\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    AE.eval()\n",
    "    prvs_loss_for_AE_updated = 0\n",
    "    for sensor_values, _ in eval_loader[0]:\n",
    "        predicted_sensor_values = AE(sensor_values.to(device).float())\n",
    "        prvs_loss_for_AE_updated += criteria_AE(sensor_values.to(device).float(),\n",
    "                                                predicted_sensor_values.to(device)).item() * sensor_values.size(0)\n",
    "    prvs_loss_for_AE_updated /= len(eval_loader[0].dataset)\n",
    "    AE.train()\n",
    "\n",
    "print(prvs_loss_for_AE_updated)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for i in range(params.inner_step_for_model):\n",
    "    inner_optim.zero_grad()\n",
    "    for sensor_values, activity in client_labeled_loaders[0]:\n",
    "        encoded_sensor_values = AE.encoder(sensor_values.to(device).float())\n",
    "        predicted_activity = model(encoded_sensor_values)\n",
    "        loss = criteria_model(predicted_activity.to(device), activity.to(device))\n",
    "        loss.backward()\n",
    "        inner_optim.step()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    prvs_loss_server_model = 0\n",
    "    f1_score_server = 0\n",
    "    for sensor_values, activity in eval_loader[0]:\n",
    "        #encoded_sensor_values = AE.encoder(sensor_values.to(device).float())\n",
    "        predicted_activity = model(sensor_values.to(device).float())\n",
    "        prvs_loss_server_model += criteria_model(\n",
    "            predicted_activity, activity.to(device)).item() * sensor_values.size(0)\n",
    "        f1_score_server += f1_loss(activity, predicted_activity) * sensor_values.size(0)\n",
    "    model.train()\n",
    "    prvs_loss_server_model /= len(eval_loader[0].dataset)\n",
    "    f1_score_server /= len(eval_loader[0].dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.980321292487943\n",
      "f1: 0.10013285586776272\n"
     ]
    }
   ],
   "source": [
    "print(\"loss: \" + str(prvs_loss_server_model))\n",
    "print(\"f1: \" + str(f1_score_server))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}